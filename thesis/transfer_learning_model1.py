# -*- coding: utf-8 -*-
"""transfer_learning_model1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aHmSZvCp0gEjef2CbgYPquNqUnt51h3m
"""

import keras
from keras import models
from keras.applications.vgg16 import VGG16
from keras.models import load_model
from keras.models import Model
from keras.layers import Dense
from keras.layers import Flatten
import h5py
from matplotlib import pyplot as plt
from PIL import Image
import tables
import tensorflow as tf
import numpy as np
from keras.applications import VGG16
from keras.layers import Dropout
from keras.models import Model
from sklearn.model_selection import train_test_split
from keras.layers import GlobalAveragePooling2D
from keras.regularizers import l2

from keras.applications import ResNet50

test=ResNet50(include_top=False, input_shape=(160, 160, 3))
test.summary()

from keras.applications import DenseNet121
newmodel2=DenseNet121(include_top=False, input_shape=(160, 160, 3))
for layer in newmodel2.layers:
	layer.trainable = False
newmodel2.summary()
x=GlobalAveragePooling2D()(newmodel2.layers[-1].output)
#x= Flatten()(newmodel2.layers[-1].output)
x = Dense(1024, activation='relu')(x)
#x = dropout1(x)
x = Dense(1024, activation='relu')(x)
#x = dropout2(x)
#x2 = dropout1(class2)
x = Dense(512, activation='relu')(x)
x= Dense(4, activation='softmax')(x)
#output = Dense(2, activation='softmax')(class1)
newmodel2 = Model(inputs=newmodel2.inputs, outputs=x)
newmodel2.summary()

newmodel2.summary()

x=GlobalAveragePooling2D()(newmodel2.layers[-1].output)
#x= Flatten()(newmodel2.layers[-1].output)
x = Dense(1024, activation='relu')(x)
#x = dropout1(x)
x = Dense(1024, activation='relu')(x)
#x = dropout2(x)
#x2 = dropout1(class2)
x = Dense(512, activation='relu')(x)
x= Dense(4, activation='softmax')(x)
#output = Dense(2, activation='softmax')(class1)
newmodel2 = Model(inputs=newmodel2.inputs, outputs=x)
newmodel2.summary()

from keras.applications import MobileNetV2

from keras.applications import MobileNetV2
new_model = MobileNetV2(include_top=False, input_shape=(160, 160, 3))
#new_model.summary()
for layer in new_model.layers:
	layer.trainable = False
  #layer.trainable = True
new_model.summary()

new_model = MobileNetV2(include_top=False, input_shape=(160, 160, 3))

#new_model.summary()
for layer in new_model.layers:
	layer.trainable = False
  #layer.trainable = True
new_model.summary()

x=GlobalAveragePooling2D()(new_model.layers[-1].output)
#x= Flatten()(new_model.layers[-1].output)
x = Dense(1024, activation='relu')(x)
#x = dropout1(x)
x = Dense(512, activation='relu')(x)
#x = dropout2(x)
#x2 = dropout1(class2)
x = Dense(256, activation='relu')(x)
x= Dense(4, activation='softmax')(x)
#output = Dense(2, activation='softmax')(class1)
new_model = Model(inputs=new_model.inputs, outputs=x)
new_model.summary()

#flat1 = Flatten()(new_model.layers[-1].output)
x=GlobalAveragePooling2D()(new_model.layers[-1].output)
#x= Flatten()(new_model.layers[-1].output)
x = Dense(1024, activation='relu')(x)
#x = dropout1(x)
x = Dense(1024, activation='relu')(x)
#x = dropout2(x)
#x2 = dropout1(class2)
x = Dense(512, activation='relu')(x)
x= Dense(4, activation='softmax')(x)
#output = Dense(2, activation='softmax')(class1)
new_model = Model(inputs=new_model.inputs, outputs=x)
new_model.summary()

VGGmodel = VGG16(include_top=False, input_shape=(160, 160, 3))

VGGmodel = VGG16(include_top=False, input_shape=(160, 160, 3))
for layer in VGGmodel.layers:
	layer.trainable = False
  #layer.trainable = True
VGGmodel.summary()
dropout1 = Dropout(0.5)
dropout2 = Dropout(0.5)
flat1 = Flatten()(VGGmodel.layers[-1].output)
#flat1=GlobalAveragePooling2D()(VGGmodel.layers[-1].output)
x = Dense(1024, activation='relu')(flat1)
#x = dropout1(x)
x = Dense(256, activation='relu')(x)
#x = dropout2(x)
#x2 = dropout1(class2)
x= Dense(4, activation='softmax')(x)
#output = Dense(2, activation='softmax')(class1)
model = Model(inputs=VGGmodel.inputs, outputs=x)
model.summary()

VGGmodel.summary()

dropout1 = Dropout(0.5)
dropout2 = Dropout(0.5)
flat1 = Flatten()(VGGmodel.layers[-1].output)
#flat1=GlobalAveragePooling2D()(VGGmodel.layers[-1].output)
x = Dense(1024, activation='relu')(flat1)
#x = dropout1(x)
x = Dense(256, activation='relu')(x)
#x = dropout2(x)
#x2 = dropout1(class2)
x= Dense(4, activation='softmax')(x)
#output = Dense(2, activation='softmax')(class1)
model = Model(inputs=VGGmodel.inputs, outputs=x)
model.summary()

new_model=models.Sequential()
new_model.add(my_model)
new_model.layers[0].trainable=False
new_model.add(Flatten())
new_model.add(Dense(1024, activation='relu'))
new_model.add(Dense(4, activation='softmax'))
new_model.summary()

hdf5_file = tables.open_file('x_train.h5', mode='r')
x_train = np.array(hdf5_file.root.x_train)
hdf5_file.close()
print(x_train.shape)

hdf5_file = tables.open_file('y_train.h5', mode='r')
y_train_6 = np.array(hdf5_file.root.y_train)
hdf5_file.close()
print(y_train_6.shape)

hdf5_file = tables.open_file('x_test.h5', mode='r')
x_test = np.array(hdf5_file.root.x_test)
hdf5_file.close()
print(x_test.shape)

hdf5_file = tables.open_file('y_test.h5', mode='r')
y_test_6 = np.array(hdf5_file.root.y_test)
hdf5_file.close()
print(y_test_6.shape)

"""## Jan 26

## Load data
"""

rs=1

hdf5_file = tables.open_file('x_asian.h5', mode='r')
x_asian = np.array(hdf5_file.root.x_asian)
hdf5_file.close()
print(x_asian.shape)

hdf5_file = tables.open_file('y_asian.h5', mode='r')
y_asian = np.array(hdf5_file.root.y_asian)
hdf5_file.close()
print(y_asian.shape)

new=[]
for item in y_asian:
  
  if np.argmax(item)==0:
    new.append([1,0,0,0])
  if np.argmax(item)==1:
    new.append([0,1,0,0])
  if np.argmax(item)==2:
    new.append([0,0,1,0])
new=np.array(new)
print(new.shape)
#print(y_asian)

y_asian=new

import random
k=random.randint(1,322-130)
k

x_test_asian=x_asian[k:k+130]
y_test_asian=y_asian[k:k+130]
tuple1=[]
for i in range (k,k+130):
  tuple1.append(i)
tuple1=tuple(tuple1)


x_train_asian=np.delete(x_asian,tuple1,axis=0)
y_train_asian=np.delete(y_asian,tuple1,axis=0)
#y_train_asian=y_asian-y_test_asian
x_train_asian.shape, y_train_asian.shape
x_train_asian.shape, y_train_asian.shape,x_test_asian.shape,y_test_asian.shape

y_test_asian

rs=100

hdf5_file = tables.open_file('x_bored.h5', mode='r')
x_bored = np.array(hdf5_file.root.x_bored)
hdf5_file.close()
print(x_bored.shape)

hdf5_file = tables.open_file('y_bored.h5', mode='r')
y_bored = np.array(hdf5_file.root.y_bored)
hdf5_file.close()
print(y_bored.shape)

#5 emotion
y_bored=[]
for i in range (75):
  #y_bored.append([1,0,0])
  #y_bored.append([1,0,0,0])
  y_bored.append([1,0,0,0,0])
  
y_bored=np.array(y_bored)
y_bored.shape

xbored_train, xbored_test, ybored_train, ybored_test = train_test_split(x_bored, y_bored, 
                                                    train_size=0.6, 
                                                    random_state=rs)
xbored_train.shape,xbored_test.shape,ybored_train.shape,ybored_test.shape

hdf5_file = tables.open_file('x_confused.h5', mode='r')
x_confused = np.array(hdf5_file.root.x_confused)
hdf5_file.close()
print(x_confused.shape)

hdf5_file = tables.open_file('y_confused.h5', mode='r')
y_confused = np.array(hdf5_file.root.y_confused)
hdf5_file.close()
print(y_confused.shape)

y_confused=[]
for i in range (80):
  #y_confused.append([1,0,0,0])
  y_confused.append([0,0,0,0,1])
  
y_confused=np.array(y_confused)
y_confused.shape

xconfused_train, xconfused_test, yconfused_train, yconfused_test = train_test_split(x_confused, y_confused, 
                                                    train_size=0.6, 
                                                    random_state=rs)
xconfused_train.shape

yconfused_test

x_3_train=np.concatenate((xconfused_train,xbored_train),axis=0)
x_3_test=np.concatenate((xconfused_test,xbored_test),axis=0)
x_3_train.shape,x_3_test.shape
y_3_train=np.concatenate((yconfused_train,ybored_train),axis=0)
y_3_test=np.concatenate((yconfused_test,ybored_test),axis=0)
x_3_train.shape,x_3_test.shape,y_3_train.shape,y_3_test.shape

y_3_test

hdf5_file = tables.open_file('Kaggle_happy.h5', mode='r')
Kaggle_happy= np.array(hdf5_file.root.Kaggle_happy)
hdf5_file.close()
print(Kaggle_happy.shape)

hdf5_file = tables.open_file('Kaggle_surprise.h5', mode='r')
Kaggle_surprise = np.array(hdf5_file.root.Kaggle_surprise)
hdf5_file.close()
print(Kaggle_surprise.shape)

hdf5_file = tables.open_file('x_happy.h5', mode='r')
x_happy = np.array(hdf5_file.root.x_happy)
hdf5_file.close()
print(x_happy.shape)

hdf5_file = tables.open_file('y_happy.h5', mode='r')
y_happy = np.array(hdf5_file.root.y_happy)
hdf5_file.close()
print(y_happy.shape)

y_happy

y_happy=[]
for i in range (183):
#for i in range (83):
  #y_happy.append([0,1,0,0])
  y_happy.append([0,1,0,0,0])
  
y_happy=np.array(y_happy)
y_happy.shape

x_happy=np.concatenate((x_happy,Kaggle_happy),axis=0)
x_happy.shape

xhappy_train, xhappy_test, yhappy_train, yhappy_test = train_test_split(x_happy, y_happy, 
                                                    train_size=0.6, 
                                                    random_state=rs)
xhappy_train.shape,yhappy_train.shape

yhappy_test.shape

hdf5_file = tables.open_file('x_surprised.h5', mode='r')
x_surprised= np.array(hdf5_file.root.x_surprised)
hdf5_file.close()
print(x_surprised.shape)

hdf5_file = tables.open_file('y_surprised.h5', mode='r')
y_surprised = np.array(hdf5_file.root.y_surprised)
hdf5_file.close()
print(y_surprised.shape)

x_surprised=np.concatenate((x_surprised,Kaggle_surprise),axis=0)
x_surprised.shape

y_surprised=[]
for i in range (179):
  #y_surprised.append([0,0,1,0])
  y_surprised.append([0,0,1,0,0])
  
y_surprised=np.array(y_surprised)
y_surprised.shape

y_surprised

xsurprised_train, xsurprised_test, ysurprised_train, ysurprised_test = train_test_split(x_surprised, y_surprised, 
                                                    train_size=0.6, 
                                                    random_state=rs)
xsurprised_train.shape,ysurprised_train.shape

ysurprised_test.shape

hdf5_file = tables.open_file('neutral.h5', mode='r')
x_neutral= np.array(hdf5_file.root.neutral)
hdf5_file.close()
print(x_neutral.shape)

x_neutral=x_neutral[0:80]
x_neutral.shape

y_neutral=[]
for i in range (151):
  y_neutral.append([0,0,0,1,0])
  #y_neutral.append([0,0,0,1])
y_neutral=np.array(y_neutral)
y_neutral.shape

xneutral_train, xneutral_test, yneutral_train, yneutral_test = train_test_split(x_neutral, y_neutral, 
                                                    train_size=0.6, 
                                                    random_state=rs)
xneutral_train.shape,yneutral_train.shape,yneutral_test.shape

#160*160
x_train=np.concatenate((x_train_asian,xbored_train,xconfused_train,xhappy_train,xsurprised_train),axis=0)
x_test=np.concatenate((x_test_asian,xbored_test,xconfused_test,xhappy_test,xsurprised_test),axis=0)
y_train=np.concatenate((y_train_asian,ybored_train,yconfused_train,yhappy_train,ysurprised_train),axis=0)
y_test=np.concatenate((y_test_asian,ybored_test,yconfused_test,yhappy_test,ysurprised_test),axis=0)
x_train.shape,x_test.shape,y_train.shape,y_test.shape

#160*160 5
x_train=np.concatenate((x2bored_train,x2confused_train,xhappy_train,xsurprised_train),axis=0)
x_test=np.concatenate((x2bored_test,x2confused_test,xhappy_test,xsurprised_test),axis=0)
y_train=np.concatenate((y2bored_train,y2confused_train,yhappy_train,ysurprised_train),axis=0)
y_test=np.concatenate((y2bored_test,y2confused_test,yhappy_test,ysurprised_test),axis=0)
x_train.shape,x_test.shape,y_train.shape,y_test.shape

x_train=np.concatenate((x_train,xneutral_train),axis=0)
x_test=np.concatenate((x_test,xneutral_test),axis=0)
y_train=np.concatenate((y_train,yneutral_train),axis=0)
y_test=np.concatenate((y_test,yneutral_test),axis=0)
x_train.shape,x_test.shape,y_train.shape,y_test.shape

y_test

#80x80
x_train=np.concatenate((xbored_train,xconfused_train,xhappy_train,xsurprised_train),axis=0)
x_test=np.concatenate((xbored_test,xconfused_test,xhappy_test,xsurprised_test),axis=0)
y_train=np.concatenate((ybored_train,yconfused_train,yhappy_train,ysurprised_train),axis=0)
y_test=np.concatenate((ybored_test,yconfused_test,yhappy_test,ysurprised_test),axis=0)
x_train.shape,x_test.shape,y_train.shape,y_test.shape

x_train.shape,x_test.shape,y_train.shape,y_test.shape

import matplotlib.pyplot as plt
k=-1
plt.imshow(x_train[k]/255)
plt.show()
print(y_train[k])

#plt.imshow(x_train_grey[k]/255)
#plt.show()

plt.imshow(x_test[k]/255)
plt.show()
print(y_test[k])

#plt.imshow(x_test_grey[k]/255)
#plt.show()

"""Load data confuse vs bored

"""

rs=200

hdf5_file = tables.open_file('x2_asian.h5', mode='r')
x2_asian = np.array(hdf5_file.root.x2_asian)
hdf5_file.close()
print(x2_asian.shape)

hdf5_file = tables.open_file('y2_asian.h5', mode='r')
y2_asian = np.array(hdf5_file.root.y2_asian)
hdf5_file.close()
print(y2_asian.shape)

import random
k=random.randint(1,161-60)
k
x2_test_asian=x2_asian[k:k+60]
y2_test_asian=y2_asian[k:k+60]
tuple1=[]
for i in range (k,k+60):
  tuple1.append(i)
tuple1=tuple(tuple1)


x2_train_asian=np.delete(x2_asian,tuple1,axis=0)
y2_train_asian=np.delete(y2_asian,tuple1,axis=0)
#y_train_asian=y_asian-y_test_asian
x2_train_asian.shape, y2_train_asian.shape
x2_train_asian.shape, y2_train_asian.shape,x2_test_asian.shape,y2_test_asian.shape

hdf5_file = tables.open_file('x2_bored.h5', mode='r')
x2_bored = np.array(hdf5_file.root.x2_bored)
hdf5_file.close()
print(x2_bored.shape)

y_bored=[]
for i in range (125):
  #y_bored.append([1,0,0])
  #y_bored.append([1,0,0,0])
  #y_bored.append([1,0,0,0,0])
  y_bored.append([1,0])
  
y_bored=np.array(y_bored)
y_bored.shape

x2bored_train, x2bored_test, y2bored_train, y2bored_test = train_test_split(x2_bored, y_bored, 
                                                    train_size=0.6, 
                                                    random_state=rs)
x2bored_train.shape,x2bored_test.shape,y2bored_train.shape,y2bored_test.shape

hdf5_file = tables.open_file('x2_confused.h5', mode='r')
x2_confused = np.array(hdf5_file.root.x2_confused)
hdf5_file.close()
print(x2_confused.shape)

y_confused=[]
for i in range (124):
  #y_confused.append([1,0,0,0])
  #y_confused.append([0,0,0,0,1])
  y_confused.append([0,1])
  
y_confused=np.array(y_confused)
y_confused.shape

x2confused_train, x2confused_test, y2confused_train, y2confused_test = train_test_split(x2_confused, y_confused, 
                                                    train_size=0.6, 
                                                    random_state=rs)
x2confused_train.shape,x2confused_test.shape

x_3_train=np.concatenate((x2confused_train,x2bored_train),axis=0)
x_3_test=np.concatenate((x2confused_test,x2bored_test),axis=0)
x_3_train.shape,x_3_test.shape
y_3_train=np.concatenate((y2confused_train,y2bored_train),axis=0)
y_3_test=np.concatenate((y2confused_test,y2bored_test),axis=0)
x_3_train.shape,x_3_test.shape,y_3_train.shape,y_3_test.shape

hdf5_file = tables.open_file('x2_bored.h5', mode='r')
x2_bored = np.array(hdf5_file.root.x2_bored)
hdf5_file.close()
print(x2_bored.shape)

hdf5_file = tables.open_file('y2_bored', mode='r')
y2_bored = np.array(hdf5_file.root.y2_bored)
hdf5_file.close()
print(y2_bored.shape)
x2bored_train, x2bored_test, y2bored_train, y2bored_test = train_test_split(x2_bored, y2_bored, 
                                                    train_size=0.6, 
                                                    random_state=rs)
x2bored_train.shape,x2bored_test.shape,y2bored_train.shape,y2bored_test.shape

hdf5_file = tables.open_file('x2_confused.h5', mode='r')
x2_confused = np.array(hdf5_file.root.x2_confused)
hdf5_file.close()
print(x2_confused.shape)

hdf5_file = tables.open_file('y2_confused', mode='r')
y2_confused = np.array(hdf5_file.root.y2_confused)
hdf5_file.close()
print(y2_confused.shape)
x2confused_train, x2confused_test, y2confused_train, y2confused_test = train_test_split(x2_confused, y2_confused, 
                                                    train_size=0.6, 
                                                    random_state=rs)
x2confused_train.shape,x2confused_test.shape

x2_train=np.concatenate((x2_train_asian,x2bored_train,x2confused_train),axis=0)
x2_test=np.concatenate((x2_test_asian,x2bored_test,x2confused_test),axis=0)
y2_train=np.concatenate((y2_train_asian,y2bored_train,y2confused_train),axis=0)
y2_test=np.concatenate((y2_test_asian,y2bored_test,y2confused_test),axis=0)
x2_train.shape,x2_test.shape,y2_train.shape,y2_test.shape

import matplotlib.pyplot as plt
k=0
plt.imshow(x2_train[k]/255)
plt.show()
print(y2_train[k])

#plt.imshow(x_train_grey[k]/255)
#plt.show()

plt.imshow(x2_test[k]/255)
plt.show()
print(y2_test[k])

#plt.imshow(x_test_grey[k]/255)
#plt.show()

"""## Model: Vgg16

freeze first 5
"""

VGGmodel = VGG16(include_top=False, input_shape=(160, 160, 3))
for layer in VGGmodel.layers:
	layer.trainable = False
  #layer.trainable = True
VGGmodel.summary()

"""freeze first 4"""

VGGmodel = VGG16(include_top=False, input_shape=(160, 160, 3))
for layer in VGGmodel.layers[:-12]:
	layer.trainable = False
  #layer.trainable = True
VGGmodel.summary()

dropout1 = Dropout(0.5)
dropout2 = Dropout(0.5)
dropout3=Dropout(0.5)
flat1 = Flatten()(VGGmodel.layers[-1].output)
x = Dense(512, kernel_regularizer=l2(1e-4), activation='relu')(flat1)
x = Dense(512, activation='relu')(x)
x = dropout1(x)
x = Dense(512, activation='relu')(x)
x = dropout2(x)
x= Dense(6, activation='softmax')(x)

model_1 = Model(inputs=VGGmodel.inputs, outputs=x)
model_1.summary()

dropout1 = Dropout(0.5)
dropout2 = Dropout(0.5)
dropout3=Dropout(0.5)
flat1 = Flatten()(VGGmodel.layers[-1].output)
x = Dense(512, kernel_regularizer=l2(0.03), bias_regularizer=l2(0.03),activation='relu')(flat1)
x=dropout3(x)
x = Dense(512, activation='relu')(x)
#x = dropout1(x)
x = Dense(512, activation='relu')(x)
#x = dropout2(x)
x= Dense(2, activation='softmax')(x)
model_2 = Model(inputs=VGGmodel.inputs, outputs=x)
model_2.summary()

"""## VGG16 Test"""



from keras.preprocessing.image import ImageDataGenerator
train_datagen=ImageDataGenerator(shear_range=0.15,zoom_range=0.15,rotation_range=20,horizontal_flip=True)
#train_datagen.fit(x_train)
train_datagen.fit(x2_train)
#train_datagen.fit(x_train_grey)

opt = keras.optimizers.SGD(learning_rate=0.001)

model_1.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['CategoricalAccuracy'])

history=model_1.fit_generator(train_datagen.flow(x_train, y_train) , epochs=100, verbose=1, validation_data=(x_test, y_test))

plt.plot(history.history['loss'][2:])
plt.plot(history.history['val_loss'][2:])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

plt.plot(history.history['categorical_accuracy'][2:])
plt.plot(history.history['val_categorical_accuracy'][2:])
plt.title('model acc')
plt.ylabel('acc')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

model_1.save('model_4.h5')



model_2.save('model_2.h5')

"""Test 2

Test 3
"""

#x_emotion_test=xbored_test
#y_emotion_test=ybored_test
#x_emotion_test=xconfused_test
#y_emotion_test=yconfused_test
#x_emotion_test=xhappy_test
#y_emotion_test=yhappy_test
#x_emotion_test=xsurprised_test
#y_emotion_test=ysurprised_test
#x_emotion_test=x_3_test
#y_emotion_test=y_3_test
#x_emotion_test=xneutral_test
#y_emotion_test=yneutral_test

x_emotion_test=x2bored_test
y_emotion_test=y2bored_test
#x_emotion_test=x2confused_test
#y_emotion_test=y2confused_test
#emotions=['x3','happy','surprised','neutrual']
emotions=['bored','happy','surprised','neutrual','confused']
#x_emotion_test=x_emotion_test[:,:,:,1]
#x_emotion_test=x_emotion_test.reshape(((30, 160, 160,3)))
#x_emotion_test=x_emotion_test.reshape(((32, 160, 160,3)))
#x_emotion_test=x_emotion_test.reshape(((74, 160, 160,3)))
#x_emotion_test=x_emotion_test.reshape(((72, 160, 160,3)))
#x_emotion_test=x_emotion_test.reshape(((62, 160, 160,3)))
#x_emotion_test=x_emotion_test.reshape(((61, 160, 160,3)))



#x_emotion_test=x_emotion_test.reshape(((73, 80, 80,3)))
#x_emotion_test=x_emotion_test.reshape(((72, 80, 80,3)))

#x_emotion_test=x_emotion_test.reshape(((100, 80, 80,3)))

#x_emotion_test=np.array(np.concatenate((x_emotion_test, x_emotion_test,x_emotion_test),axis=3))

y_test_6_prediction=model_1.predict(x_emotion_test)
#y_test_6_prediction=model_2.predict(x_emotion_test)
y_test_6_prediction_categories=[]
for i in range (y_test_6_prediction.shape[0]):
  #print(y_test_2[i])
  idx=np.argmax(y_test_6_prediction[i])
  y_test_6_prediction_categories.append(emotions[idx])
print(y_test_6_prediction)
print(y_test_6_prediction_categories)
y_test_categories=[]
for i in range (y_emotion_test.shape[0]):
  #print(y_test_2[i])
  idx=np.argmax(y_emotion_test[i])
  y_test_categories.append(emotions[idx])
print(y_test_categories)

total=0
correct=0
for i in range (len(y_test_categories)):
  total+=1
  if y_test_categories[i]==y_test_6_prediction_categories[i]:
    correct+=1
print(correct/total)

y_test_categories=[]
for i in range (y_test.shape[0]):
  #print(y_test_2[i])
  idx=np.argmax(y_test[i])
  y_test_categories.append(idx)
y_test_categories

x_emotion_test=x_test
#x_emotion_test=x_emotion_test.reshape(((399, 160, 160,3)))
#x_emotion_test=x_emotion_test.reshape(((160, 160, 160,3)))
y_test_6_prediction=model_1.predict(x_emotion_test)
y_test_6_prediction.shape
y_test_6_prediction_categories=[]
for i in range (y_test_6_prediction.shape[0]):
  #print(y_test_2[i])
  idx=np.argmax(y_test_6_prediction[i])
  y_test_6_prediction_categories.append(idx)
y_test_6_prediction_categories

def plot_confusion_matrix(cm):
    # plot the confusion matrix
    plt.figure(figsize=(6,6))
    plt.matshow(cm, fignum=1)
    
    # add labels for all targets
    num_targets = cm.shape[0]
    plt.xticks(list(range(num_targets+1)))
    plt.yticks(list(range(num_targets+1)))
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test_categories, y_test_6_prediction_categories)
#cm = confusion_matrix([1,1,1,1], [1,1,1,0])
plot_confusion_matrix(cm)

"""Test4"""

x_test.shape

x_emotion_test=xbored_test
y_emotion_test=ybored_test
#x_emotion_test=xconfused_test
#y_emotion_test=yconfused_test

emotions=['bored', 'confused']

x_emotion_test=x_emotion_test.reshape(((15, 160, 160,3)))
#x_emotion_test=x_emotion_test.reshape(((16, 160, 160,3)))
#x_emotion_test=x_emotion_test.reshape(((37, 160, 160,3)))
#x_emotion_test=x_emotion_test.reshape(((36, 160, 160,3)))
#x_emotion_test=x_emotion_test.reshape(((168, 160, 160,3)))
y_test_6_prediction=model_1.predict(x_emotion_test)

print(y_test_6_prediction)

y_prediction_step2=[]
y_label_step2=[]
for i in range (y_test_6_prediction.shape[0]):
  #print(y_test_2[i])
  idx=np.argmax(y_test_6_prediction[i])
  if idx==0:
    y_prediction_step2.append(x_emotion_test[i])
    y_label_step2.append(y_emotion_test[i])
y_prediction_step2=np.array(y_prediction_step2)
y_label_step2=np.array(y_label_step2)

print(x_emotion_test.shape,y_prediction_step2.shape)
print(y_emotion_test.shape,y_label_step2.shape)

y_prediction_step2_output=model_2.predict(y_prediction_step2)
y_test_6_prediction_categories=[]
for i in range (y_prediction_step2_output.shape[0]):
  #print(y_test_2[i])
  idx=np.argmax(y_prediction_step2_output[i])
  y_test_6_prediction_categories.append(emotions[idx])
print(y_prediction_step2_output)
print(y_test_6_prediction_categories)
y_test_categories=[]
for i in range (y_label_step2.shape[0]):
  #print(y_test_2[i])
  idx=np.argmax(y_label_step2[i])
  y_test_categories.append(emotions[idx])
print(y_test_categories)

print(len(y_test_6_prediction_categories),len(y_test_categories))

total=y_emotion_test.shape[0]-y_label_step2.shape[0]

correct=0
for i in range (len(y_test_categories)):
  total+=1
  if y_test_categories[i]==y_test_6_prediction_categories[i]:
    correct+=1
print(correct/total)



"""# MobileNetV2"""

from keras.applications import MobileNetV2
new_model = MobileNetV2(include_top=False, input_shape=(160, 160, 3))
#new_model.summary()
for layer in new_model.layers:
	layer.trainable = False
  #layer.trainable = True
#new_model.summary()

#new_model.summary()
for layer in new_model.layers:
	layer.trainable = False
  #layer.trainable = True
new_model.summary()

#x=GlobalAveragePooling2D()(new_model.layers[-1].output)
x= Flatten()(new_model.layers[-1].output)
x = Dense(1024, activation='relu')(x)
x = dropout1(x)
#x = Dense(512, activation='relu')(x)
#x = dropout2(x)
#x2 = dropout1(class2)
x = Dense(256, activation='relu')(x)
x= Dense(3, activation='softmax')(x)
#output = Dense(2, activation='softmax')(class1)
new_model = Model(inputs=new_model.inputs, outputs=x)
new_model.summary()

"""# Test"""



from keras.preprocessing.image import ImageDataGenerator
train_datagen=ImageDataGenerator(shear_range=0.15,zoom_range=0.15,horizontal_flip=True)
train_datagen.fit(x_train)
#train_datagen.fit(x_train_grey)
#from keras.preprocessing.image import ImageDataGenerator
test_datagen=ImageDataGenerator(shear_range=0.15,zoom_range=0.15,horizontal_flip=True)
test_datagen.fit(x_test)
#test_datagen.fit(x_test_grey)
opt = keras.optimizers.SGD(learning_rate=0.005)
new_model.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['CategoricalAccuracy'])
#print(x_train_grey.shape,y_train.shape,x_test_grey.shape,y_test.shape)

history=new_model.fit_generator(train_datagen.flow(x_train, y_train) , epochs=200, verbose=1, validation_data=train_datagen.flow(x_test, y_test))

history=new_model.fit_generator(train_datagen.flow(x_train, y_train) , epochs=200, verbose=1, validation_data=(x_test, y_test))

plt.plot(history.history['loss'][10:])
plt.plot(history.history['val_loss'][10:])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

plt.plot(history.history['categorical_accuracy'][10:])
plt.plot(history.history['val_categorical_accuracy'][10:])
plt.title('model acc')
plt.ylabel('acc')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

x_emotion_test=xbored_test
y_emotion_test=ybored_test
#x_emotion_test=xconfused_test
#y_emotion_test=yconfused_test
#x_emotion_test=xhappy_test
#y_emotion_test=yhappy_test
#x_emotion_test=xsurprised_test
#y_emotion_test=ysurprised_test
#x_emotion_test=x_3_test
#y_emotion_test=y_3_test
emotions=['bored',  'happy', 'surprised']
#x_emotion_test=x_emotion_test[:,:,:,1]
x_emotion_test=x_emotion_test.reshape(((15, 160, 160,3)))
#x_emotion_test=x_emotion_test.reshape(((16, 160, 160,3)))
#x_emotion_test=x_emotion_test.reshape(((37, 160, 160,3)))
#x_emotion_test=x_emotion_test.reshape(((36, 160, 160,3)))
#x_emotion_test=x_emotion_test.reshape(((31, 160, 160,3)))

#x_emotion_test=np.array(np.concatenate((x_emotion_test, x_emotion_test,x_emotion_test),axis=3))

y_test_6_prediction=new_model.predict(x_emotion_test)
y_test_6_prediction_categories=[]
for i in range (y_test_6_prediction.shape[0]):
  #print(y_test_2[i])
  idx=np.argmax(y_test_6_prediction[i])
  y_test_6_prediction_categories.append(emotions[idx])
print(y_test_6_prediction)
print(y_test_6_prediction_categories)
y_test_categories=[]
for i in range (y_emotion_test.shape[0]):
  #print(y_test_2[i])
  idx=np.argmax(y_emotion_test[i])
  y_test_categories.append(emotions[idx])
print(y_test_categories)

total=0
correct=0
for i in range (len(y_test_categories)):
  total+=1
  if y_test_categories[i]==y_test_6_prediction_categories[i]:
    correct+=1
print(correct/total)

plt.imshow(x_emotion_test[13]/255)
plt.show()
#print(y_train_6[k])

"""# Dense Net"""

from keras.applications import DenseNet121
newmodel2=DenseNet121(include_top=False, input_shape=(160, 160, 3))
for layer in newmodel2.layers:
	layer.trainable = False
newmodel2.summary()



dropout1 = Dropout(0.5)
x=GlobalAveragePooling2D()(newmodel2.layers[-1].output)
#x= Flatten()(newmodel2.layers[-1].output)
x = Dense(1024, activation='relu')(x)
#x = dropout1(x)
#x = Dense(1024, activation='relu')(x)
#x = dropout2(x)
#x2 = dropout1(class2)
x = Dense(256, activation='relu')(x)
x= Dense(3, activation='softmax')(x)
#output = Dense(2, activation='softmax')(class1)
newmodel2 = Model(inputs=newmodel2.inputs, outputs=x)
newmodel2.summary()

from keras.preprocessing.image import ImageDataGenerator
train_datagen=ImageDataGenerator(shear_range=0.15,zoom_range=0.15,horizontal_flip=True)
train_datagen.fit(x_train)
#train_datagen.fit(x_train_grey)
from keras.preprocessing.image import ImageDataGenerator
test_datagen=ImageDataGenerator(shear_range=0.15,zoom_range=0.15,horizontal_flip=True)
test_datagen.fit(x_test)
#test_datagen.fit(x_test_grey)
opt = keras.optimizers.SGD(learning_rate=0.005)
newmodel2.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['CategoricalAccuracy'])
#print(x_train_grey.shape,y_train.shape,x_test_grey.shape,y_test.shape)

#history=newmodel2.fit_generator(train_datagen.flow(x_train, y_train) , epochs=200, verbose=1, validation_data=train_datagen.flow(x_test, y_test))
history=newmodel2.fit_generator(train_datagen.flow(x_train, y_train) , epochs=200, verbose=1, validation_data=(x_test, y_test))

plt.plot(history.history['loss'][10:])
plt.plot(history.history['val_loss'][10:])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

plt.plot(history.history['categorical_accuracy'][10:])
plt.plot(history.history['val_categorical_accuracy'][10:])
plt.title('model acc')
plt.ylabel('acc')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

#x_emotion_test=xbored_test
#y_emotion_test=ybored_test
#x_emotion_test=xconfused_test
#y_emotion_test=yconfused_test
x_emotion_test=xhappy_test
y_emotion_test=yhappy_test
#x_emotion_test=xsurprised_test
#y_emotion_test=ysurprised_test
#x_emotion_test=x_3_test
#y_emotion_test=y_3_test
emotions=['bored', 'happy', 'surprised']
#x_emotion_test=x_emotion_test[:,:,:,1]
#x_emotion_test=x_emotion_test.reshape(((15, 160, 160,3)))
#x_emotion_test=x_emotion_test.reshape(((16, 160, 160,3)))
x_emotion_test=x_emotion_test.reshape(((37, 160, 160,3)))
#x_emotion_test=x_emotion_test.reshape(((36, 160, 160,3)))
#x_emotion_test=x_emotion_test.reshape(((31, 160, 160,3)))

#x_emotion_test=np.array(np.concatenate((x_emotion_test, x_emotion_test,x_emotion_test),axis=3))

y_test_6_prediction=newmodel2.predict(x_emotion_test)
y_test_6_prediction_categories=[]
for i in range (y_test_6_prediction.shape[0]):
  #print(y_test_2[i])
  idx=np.argmax(y_test_6_prediction[i])
  y_test_6_prediction_categories.append(emotions[idx])
print(y_test_6_prediction)
print(y_test_6_prediction_categories)
y_test_categories=[]
for i in range (y_emotion_test.shape[0]):
  #print(y_test_2[i])
  idx=np.argmax(y_emotion_test[i])
  y_test_categories.append(emotions[idx])
print(y_test_categories)

total=0
correct=0
for i in range (len(y_test_categories)):
  total+=1
  if y_test_categories[i]==y_test_6_prediction_categories[i]:
    correct+=1
print(correct/total)

y_emotion_test

x_bored.shape

x_train_single=xbored_test[:,:,:,1]
x_train_single=x_train_single.reshape(((15, 160, 160,1)))
x_test_grey=np.array(np.concatenate((x_train_single, x_train_single,x_train_single),axis=3))

y_test_6_prediction=model.predict(x_test_grey)
y_test_6_prediction_categories=[]
for i in range (y_test_6_prediction.shape[0]):
  #print(y_test_2[i])
  idx=np.argmax(y_test_6_prediction[i])
  y_test_6_prediction_categories.append(emotions[idx])
print(y_test_6_prediction)

y_test_categories=[]
for i in range (ybored_test.shape[0]):
  #print(y_test_2[i])
  idx=np.argmax(ybored_test[i])
  y_test_categories.append(emotions[idx])
print(y_test_categories)

total=0
correct=0
for i in range (len(y_test_categories)):
  total+=1
  if y_test_categories[i]==y_test_6_prediction_categories[i]:
    correct+=1
print(correct/total)

x_train_single=xbored_test[:,:,:,1]
x_train_single=x_train_single.reshape(((15, 160, 160,1)))
x_test_grey=np.array(np.concatenate((x_train_single, x_train_single,x_train_single),axis=3))
x_test_grey.shape

x_train_single=xconfused_test[:,:,:,1]
x_train_single=x_train_single.reshape(((16, 160, 160,1)))
x_test_grey=np.array(np.concatenate((x_train_single, x_train_single,x_train_single),axis=3))
x_test_grey.shape

x_train_single=xhappy_test[:,:,:,1]
x_train_single=x_train_single.reshape(((17, 160, 160,1)))
x_test_grey=np.array(np.concatenate((x_train_single, x_train_single,x_train_single),axis=3))
x_test_grey.shape

x_train_single= xsurprised_test[:,:,:,1]
x_train_single=x_train_single.reshape(((16, 160, 160,1)))
x_test_grey=np.array(np.concatenate((x_train_single, x_train_single,x_train_single),axis=3))
x_test_grey.shape

x_train_single=x_test[:,:,:,1]
x_train_single=x_train_single.reshape(((128, 160, 160,1)))
x_test_grey=np.array(np.concatenate((x_train_single, x_train_single,x_train_single),axis=3))
x_test_grey.shape

x_train_single=x_test_asian[:,:,:,1]
x_train_single=x_train_single.reshape(((64, 160, 160,1)))
x_test_grey=np.array(np.concatenate((x_train_single, x_train_single,x_train_single),axis=3))
x_test_grey.shape

import matplotlib.pyplot as plt
k=10
plt.imshow(x_surprised[k]/255)
plt.show()
#print(y_train_6[k])

plt.imshow(x_test_grey[k]/255)
plt.show()
#print(y_confused[k])

emotions=['bored', 'confused', 'happy', 'surprised']

y_test_6_prediction=model.predict(x_test_grey)
y_test_6_prediction_categories=[]
for i in range (y_test_6_prediction.shape[0]):
  #print(y_test_2[i])
  idx=np.argmax(y_test_6_prediction[i])
  y_test_6_prediction_categories.append(emotions[idx])
print(y_test_6_prediction)
y_test_6_prediction_categories

y_test_categories=[]
for i in range (y_test_asian.shape[0]):
  #print(y_test_2[i])
  idx=np.argmax(y_test_asian[i])
  y_test_categories.append(emotions[idx])
len(y_test_categories)

y_test_categories=[]
for i in range (y_test.shape[0]):
  #print(y_test_2[i])
  idx=np.argmax(y_test[i])
  y_test_categories.append(emotions[idx])
len(y_test_categories)

y_test_categories=[]
for i in range (y_bored.shape[0]):
  #print(y_test_2[i])
  idx=np.argmax(y_bored[i])
  y_test_categories.append(emotions[idx])
y_test_categories

y_test_categories=[]
for i in range (y_confused.shape[0]):
  #print(y_test_2[i])
  idx=np.argmax(y_confused[i])
  y_test_categories.append(emotions[idx])
y_test_categories

y_test_categories=[]
for i in range (y_happy.shape[0]):
  #print(y_test_2[i])
  idx=np.argmax(y_happy[i])
  y_test_categories.append(emotions[idx])
y_test_categories

y_test_categories=[]
for i in range (y_surprised.shape[0]):
  #print(y_test_2[i])
  idx=np.argmax(y_surprised[i])
  y_test_categories.append(emotions[idx])
y_test_categories

total=0
correct=0
for i in range (len(y_test_categories)):
  total+=1
  if y_test_categories[i]==y_test_6_prediction_categories[i]:
    correct+=1
print(correct/total)

y_test_6_categories=[]
for i in range (y_test_6.shape[0]):
  #print(y_test_2[i])
  idx=np.argmax(y_test_6[i])
  y_test_6_categories.append(idx)
y_test_6_categories

y_test_6_prediction

y_test_6_prediction=model.predict(x_test)

y_test_6_prediction

y_test_6_prediction_categories=[]
for i in range (y_test_6.shape[0]):
  #print(y_test_2[i])
  idx=np.argmax(y_test_6[i])
  y_test_6_prediction_categories.append(idx)
y_test_6_prediction_categories

y_test_categories=[]
for i in range (y_surprised.shape[0]):
  #print(y_test_2[i])
  idx=np.argmax(y_surprised[i])
  y_test_categories.append(emotions[idx])
y_test_6_prediction_categories=[]
for i in range (y_test_6.shape[0]):
  #print(y_test_2[i])
  idx=np.argmax(y_test_6[i])
  y_test_6_prediction_categories.append(idx)
y_test_6_prediction_categories
def plot_confusion_matrix(cm):
    # plot the confusion matrix
    plt.figure(figsize=(6,6))
    plt.matshow(cm, fignum=1)
    
    # add labels for all targets
    num_targets = cm.shape[0]
    plt.xticks(list(range(num_targets+1)))
    plt.yticks(list(range(num_targets+1)))
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test_categories, y_test_6_prediction_categories)
#cm = confusion_matrix([1,1,1,1], [1,1,1,0])
plot_confusion_matrix(cm)

def plot_confusion_matrix(cm):
    # plot the confusion matrix
    plt.figure(figsize=(6,6))
    plt.matshow(cm, fignum=1)
    
    # add labels for all targets
    num_targets = cm.shape[0]
    plt.xticks(list(range(num_targets+1)))
    plt.yticks(list(range(num_targets+1)))

y_test_6_categories=y_test_6

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test_categories, y_test_6_prediction_categories)
#cm = confusion_matrix([1,1,1,1], [1,1,1,0])
plot_confusion_matrix(cm)

emotions=['bored', 'confused', 'enlightened', 'happy', 'surprised', 'unsatisfied']

img=Image.open('_unsatisfied_face.jpg')
img = img.resize((160, 160))
img = np.array(img)

import matplotlib.pyplot as plt
plt.imshow(img/255)
plt.show()

inputarray = []
#arr = np.array(x_test[-1])
arr = np.array(img)
inputarray = np.append(inputarray, arr)
inputarray = np.array(inputarray, dtype='float32')
inputarray = inputarray.reshape((1, 160, 160, 3))
inputarray.shape

prediction=model.predict(inputarray)

prediction

idx = np.argmax(prediction)
print(emotions[idx])

